{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU2U6VNjBhlU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import requests\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import Tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_csv = \"https://raw.githubusercontent.com/paulskeie/stadnamn/main/stadnamn.csv\"\n",
        "def get_stadnamn(url_csv):\n",
        "  r = requests.get(url_csv)\n",
        "  data = r.text\n",
        "  return data"
      ],
      "metadata": {
        "id": "jxWREU0tPdSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = get_stadnamn(url_csv)"
      ],
      "metadata": {
        "id": "eHDEKgPmQPub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(txt,tokens,start_stop_chars):\n",
        "  sn_tokens=[tokens[start_stop_chars[0]]]\n",
        "  for c in txt:\n",
        "    sn_tokens.append(tokens[c])\n",
        "  sn_tokens.append(tokens[start_stop_chars[1]])\n",
        "  return sn_tokens\n",
        "\n",
        "counter=Counter(data)\n",
        "\n",
        "# Find the longest place name and assign the number of characters to maxlen\n",
        "max_len=0\n",
        "for sn in data.splitlines():\n",
        "  if len(sn) > max_len:\n",
        "    max_len=len(sn)\n",
        "    max_len_sn=sn\n",
        "# Add one to account for the start token, the end token shall not be a feature, only a target\n",
        "max_len+=1\n",
        "\n",
        "\n",
        "# Use characters that don't occur in the place names as start and stop characters.\n",
        "start_stop_chars=['@','$']\n",
        "\n",
        "# Here we make a dictionary mapping tokens to characters. Later we will zero pad which is why we start at 1\n",
        "tokens=dict([(x,i+1) for i,x in enumerate(sorted(start_stop_chars+list(counter.keys())))])\n",
        "vocab_size = len(tokens)+1"
      ],
      "metadata": {
        "id": "OamqkyTcQeYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "placenames=data.split(\"\\n\")"
      ],
      "metadata": {
        "id": "IAKp8O-lkHok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_placename_index(placenames):\n",
        "  ith_example=0\n",
        "  placename_index={}\n",
        "  for i,placename in enumerate(placenames):\n",
        "    len_placename=len(placename)\n",
        "    jth_example=0\n",
        "    for j in range(len_placename+1):\n",
        "      placename_index[ith_example]=(i,jth_example)\n",
        "      ith_example+=1\n",
        "      jth_example+=1\n",
        "  n_examples = ith_example\n",
        "  return n_examples,placename_index"
      ],
      "metadata": {
        "id": "wIZPJuyLUSc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_test_split_indices(length, train_fraction=0.8):\n",
        "    \"\"\"\n",
        "    Generates training and testing indices for a given dataset size.\n",
        "\n",
        "    Args:\n",
        "    - length (int): The total number of items in the dataset.\n",
        "    - train_fraction (float): Fraction of the dataset to be used for training.\n",
        "\n",
        "    Returns:\n",
        "    - index_train (list): Indices for the training set.\n",
        "    - index_test (list): Indices for the testing set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the number of training samples\n",
        "    train_size = int(length * train_fraction)\n",
        "\n",
        "    # Generate all indices\n",
        "    indices = list(range(length))\n",
        "\n",
        "    # Shuffle the indices\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    index_train = indices[:train_size]\n",
        "    index_test = indices[train_size:]\n",
        "\n",
        "    return index_train, index_test\n"
      ],
      "metadata": {
        "id": "yAoGzXEkzpTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_train, index_test = train_test_split_indices(len(placenames))"
      ],
      "metadata": {
        "id": "Xqk-QDyQdDEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "placenames_train = [placenames[idx] for idx in index_train]\n",
        "placenames_test = [placenames[idx] for idx in index_test]"
      ],
      "metadata": {
        "id": "j2jYN8bj8Ilq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_jth_example_in_placename(j,placename, tokens, start_stop_chars):\n",
        "  placename_tokens = tokenize(placename, tokens, start_stop_chars)\n",
        "  len_placename_tokens=len(placename_tokens)\n",
        "  if j > len_placename_tokens - 2:\n",
        "    return None\n",
        "  features = placename_tokens[:j + 1]\n",
        "  target = placename_tokens[j + 1]\n",
        "  return features,target"
      ],
      "metadata": {
        "id": "fTFLtu-ee5y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(\"Bulken\", tokens, start_stop_chars)"
      ],
      "metadata": {
        "id": "YHG8nANZg_wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_jth_example_in_placename(4,\"Bulken\",tokens, start_stop_chars)"
      ],
      "metadata": {
        "id": "gBkPKXmxfg81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens.keys()"
      ],
      "metadata": {
        "id": "MBhIf-yyRtIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens.values()"
      ],
      "metadata": {
        "id": "mm5KgI3BTGpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PlaceNameDataset(Dataset):\n",
        "    def __init__(self, placenames, tokens, start_stop_chars, max_len):\n",
        "        self.placenames = placenames\n",
        "        self.tokens = tokens\n",
        "        self.start_stop_chars = start_stop_chars\n",
        "        self.max_len = max_len\n",
        "        self.n_examples,self.placename_index = build_placename_index(placenames)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index < 0 or index >= self.__len__():\n",
        "            raise IndexError(\"Index out of range\")\n",
        "\n",
        "        # Find which placename the index corresponds to\n",
        "        placename_index,local_index = self.placename_index[index]\n",
        "\n",
        "        placename = self.placenames[placename_index]\n",
        "\n",
        "        # Get jth example in placename\n",
        "        features, target = get_jth_example_in_placename(local_index,placename,self.tokens, self.start_stop_chars)\n",
        "\n",
        "        return features, target\n"
      ],
      "metadata": {
        "id": "vOH11vS-Q-Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PlaceNameDataset(placenames_train,tokens,start_stop_chars,max_len)\n",
        "test_dataset = PlaceNameDataset(placenames_test,tokens,start_stop_chars,max_len)"
      ],
      "metadata": {
        "id": "kHgcrRNiGUgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length=30"
      ],
      "metadata": {
        "id": "bacYwPUQScBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch, max_len=max_seq_length):\n",
        "    # Separate features and targets\n",
        "    feature_batch, target_batch = zip(*batch)\n",
        "\n",
        "    # Process features: Pad/truncate each sequence to max_len\n",
        "    processed_features = []\n",
        "    for seq in feature_batch:\n",
        "      seq = torch.tensor(seq)\n",
        "      if len(seq) < max_len:\n",
        "          # Pad sequence if shorter than max_len\n",
        "          padded_seq = torch.cat([torch.full((max_len - len(seq),), 0),seq])\n",
        "      else:\n",
        "          # Truncate sequence if longer than max_len\n",
        "          padded_seq = seq[-max_len:]\n",
        "      processed_features.append(padded_seq)\n",
        "\n",
        "    # Stack all processed features and targets\n",
        "    features = torch.stack(processed_features)\n",
        "    targets = torch.tensor(target_batch)\n",
        "\n",
        "    return features, targets"
      ],
      "metadata": {
        "id": "3AzBVrmqB1PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create DataLoaders with custom collate_fn\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, collate_fn=collate_fn,shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "kZ4Ecwy6HtkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataloader)"
      ],
      "metadata": {
        "id": "zQJQ1TdYrmmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "id": "hI0kFjMxrtFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [batch_size, sequence_length]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "BrEhZSges9_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb=nn.Embedding(vocab_size,2)\n",
        "out=emb(X)\n",
        "out.size()"
      ],
      "metadata": {
        "id": "6kXNDpKYtah3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleEmbedding(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim,max_seq_length,fan_out_dim_linear1):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.linear1 = nn.Linear(max_seq_length*embedding_dim,fan_out_dim_linear1)\n",
        "    self.bn1 = nn.BatchNorm1d(fan_out_dim_linear1)\n",
        "    self.linear2 = nn.Linear(fan_out_dim_linear1,vocab_size)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self) -> None:\n",
        "    initrange = 0.1\n",
        "    self.emb.weight.data.uniform_(-initrange, initrange)\n",
        "    self.linear1.bias.data.zero_()\n",
        "    self.linear1.weight.data.uniform_(-initrange, initrange)\n",
        "    self.linear2.bias.data.zero_()\n",
        "    self.linear2.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.emb(x)\n",
        "    x = x.view(x.size(0),-1)\n",
        "    x = self.linear1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(x)\n",
        "    logits = self.linear2(x)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "9McZbeLN0HMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SimpleEmbedding(vocab_size,8,max_seq_length,120)"
      ],
      "metadata": {
        "id": "bpJIZUfQQTHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "1tJ0cilrtLCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "G1-MQW1bTd7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "logits = model(X.to(device))\n",
        "loss = loss_fn(logits,y.to(device))\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "OiB_wnt8T92c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.item()"
      ],
      "metadata": {
        "id": "zDEfIXwFjGjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "3adlUnhC54Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "batch_number = 0\n",
        "for X,y in train_dataloader:\n",
        "  X=X.to(device)\n",
        "  y=y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  logits = model(X)\n",
        "  loss = loss_fn(logits,y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  batch_number+=1\n",
        "\n",
        "  # Convert logits to predicted class indices\n",
        "  _, predicted = torch.max(logits.data, 1)\n",
        "  total += y.size(0)\n",
        "  correct += (predicted == y).sum().item()\n",
        "\n",
        "  if batch_number % 1000 == 0:\n",
        "    print(batch_number,loss.item())\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Batch: {batch_number}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "  if batch_number % 40000 == 0:\n",
        "    break"
      ],
      "metadata": {
        "id": "K5nLLQuDjVco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.emb.weight.detach().cpu().numpy()\n",
        "token_to_char = {token: char for char, token in tokens.items()}"
      ],
      "metadata": {
        "id": "mgL57xbw1Lbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[10]"
      ],
      "metadata": {
        "id": "4utvsjUVAN5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot each embedding\n",
        "plt.figure(figsize=(10, 10))\n",
        "for token, char in token_to_char.items():\n",
        "    x, y = embeddings[token]  # Get the 2D coordinates\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(char, (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "plt.xlabel('Embedding Dimension 1')\n",
        "plt.ylabel('Embedding Dimension 2')\n",
        "plt.title('Character Embeddings')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l6zaKLrX1RxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleTransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, max_seq_length, fan_out_dim_linear1, nhead, num_encoder_layers, dim_feedforward):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=nhead, dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        self.linear1 = nn.Linear(max_seq_length * embedding_dim, fan_out_dim_linear1)\n",
        "        self.bn1 = nn.BatchNorm1d(fan_out_dim_linear1)\n",
        "        self.linear2 = nn.Linear(fan_out_dim_linear1, vocab_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.emb.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear1.bias.data.zero_()\n",
        "        self.linear1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear2.bias.data.zero_()\n",
        "        self.linear2.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "        x = x.permute(1, 0, 2)  # Transformer expects src (L, N, E) format\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # Revert to (N, L, E) for linear layers\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        logits = self.linear2(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "_4jGHNzjAaRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = SimpleTransformerModel(123,8,10,120,4,2,120).to(device)\n",
        "model = SimpleTransformerModel(vocab_size=123, embedding_dim=8, max_seq_length=30, fan_out_dim_linear1=120, nhead=4, num_encoder_layers=4, dim_feedforward=120).to(device)\n"
      ],
      "metadata": {
        "id": "wBxYWBNHAeuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "-NRY254hDV8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "batch_number = 0\n",
        "for X,y in train_dataloader:\n",
        "  X=X.to(device)\n",
        "  y=y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  logits = model(X)\n",
        "  loss = loss_fn(logits,y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  batch_number+=1\n",
        "\n",
        "  # Convert logits to predicted class indices\n",
        "  _, predicted = torch.max(logits.data, 1)\n",
        "  total += y.size(0)\n",
        "  correct += (predicted == y).sum().item()\n",
        "\n",
        "  if batch_number % 1000 == 0:\n",
        "    print(batch_number,loss.item())\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Batch: {batch_number}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "  #if batch_number % 10000 == 0:\n",
        "  #  break"
      ],
      "metadata": {
        "id": "uJqSZq1AA1YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dataloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(X)\n",
        "\n",
        "        # Convert logits to predicted class indices\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy on the test set: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "Q0ivkQYuuc-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "PoW_NAJNGA5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p=np.arange(0.01,1,0.01)\n",
        "cce=-np.log(p)\n",
        "plt.plot(p,cce);"
      ],
      "metadata": {
        "id": "KtudVCjbg6Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_embedding=pe.pe.cpu().numpy()"
      ],
      "metadata": {
        "id": "i3fcfMrcfN2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(positional_embedding[:,0,:9])"
      ],
      "metadata": {
        "id": "NMmjuH52fwyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XX=X.cpu()"
      ],
      "metadata": {
        "id": "F1EfbbWnw0Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=8\n",
        "emb=nn.Embedding(vocab_size,embedding_dim)\n",
        "out=emb(XX).permute(1,0,2)\n",
        "print(XX.size())\n",
        "print(out.size())\n",
        "pe = PositionalEncoding(embedding_dim,0.1,max_seq_length)\n",
        "peout=pe(out)\n",
        "print(peout.size())"
      ],
      "metadata": {
        "id": "6or9d-o-Jbjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.size()"
      ],
      "metadata": {
        "id": "TCcn54j2xMve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.permute(1,0,2).size()"
      ],
      "metadata": {
        "id": "2IAdH_x2xUH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqjBhLf9hjta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MediumTransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, max_seq_length, fan_out_dim_linear1, nhead, num_encoder_layers, dim_feedforward):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=nhead, dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        self.linear1 = nn.Linear(max_seq_length * embedding_dim, fan_out_dim_linear1)\n",
        "        self.bn1 = nn.BatchNorm1d(fan_out_dim_linear1)\n",
        "        self.linear2 = nn.Linear(fan_out_dim_linear1, vocab_size)\n",
        "        self.pos_encoder = PositionalEncoding(embedding_dim, 0.1, max_seq_length)\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.emb.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear1.bias.data.zero_()\n",
        "        self.linear1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear2.bias.data.zero_()\n",
        "        self.linear2.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x) * math.sqrt(self.embedding_dim)  # Scale embedding\n",
        "        x = x.permute(1,0,2)\n",
        "        x = self.pos_encoder(x)\n",
        "        #x = x.permute(1, 0, 2)  # Transformer expects src (L, N, E) format\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # Revert to (N, L, E) for linear layers\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.linear1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        logits = self.linear2(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "njWUwtLFJpI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MediumTransformerModel(vocab_size=123, embedding_dim=4, max_seq_length=max_seq_length, fan_out_dim_linear1=64, nhead=4, num_encoder_layers=4, dim_feedforward=64).to(device)"
      ],
      "metadata": {
        "id": "hEHg7lc6KNXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "s6kXYk6LKbwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "batch_number = 0\n",
        "for X,y in train_dataloader:\n",
        "  X=X.to(device)\n",
        "  y=y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  logits = model(X)\n",
        "  loss = loss_fn(logits,y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  batch_number+=1\n",
        "\n",
        "  # Convert logits to predicted class indices\n",
        "  _, predicted = torch.max(logits.data, 1)\n",
        "  total += y.size(0)\n",
        "  correct += (predicted == y).sum().item()\n",
        "\n",
        "  if batch_number % 1000 == 0:\n",
        "    print(batch_number,loss.item())\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Batch: {batch_number}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "  if batch_number % 10000 == 0:\n",
        "    break"
      ],
      "metadata": {
        "id": "nThQSuMeKizA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_parameters=0\n",
        "for parameter in model.parameters():\n",
        "    par=parameter.view(-1).size()[0]\n",
        "    n_parameters+=par\n",
        "    print(par,n_parameters)"
      ],
      "metadata": {
        "id": "egV8c5EdjyoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO, try this:\n",
        "# https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "sBlF2KF9rpLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate PositionalEncoding\n",
        "d_model = 8  # Embedding dimension\n",
        "max_len = 30  # Maximum sequence length for visualization\n",
        "pe = PositionalEncoding(d_model, 0.1 ,max_len)\n",
        "\n",
        "# Generate a dummy input tensor\n",
        "seq_length = 30\n",
        "dummy_input = torch.zeros(seq_length, 1, d_model)\n",
        "\n",
        "# Get the positional encodings\n",
        "with torch.no_grad():\n",
        "    positional_encodings = pe(dummy_input).squeeze(1)\n",
        "\n",
        "# Convert to numpy for visualization\n",
        "positional_encodings = positional_encodings.cpu().numpy()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.pcolormesh(positional_encodings, cmap='RdBu')\n",
        "plt.xlabel('Embedding Dimensions')\n",
        "plt.ylabel('Position in Sequence')\n",
        "plt.colorbar()\n",
        "plt.title('Positional Encoding Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VLd-BUrDsX5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}